{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Player Statistics Workshop\n",
    "\n",
    "Given a dataset of NBA players performance and salary in 2014, use Python to load the dataset and compute the summary statistics for the `SALARY` field:\n",
    "\n",
    "- mean\n",
    "- median\n",
    "- mode\n",
    "- minimum\n",
    "- maximum\n",
    "\n",
    "You will need to make use of the csv module to load the data and interact with it. Computations should require only simple arithmetic. (For the purposes of this exerciese, attempt to use pure Python and no third party dependencies like Pandas - you can then compare and contrast the use of Pandas for this task later). \n",
    "\n",
    "**Bonus:**\n",
    "\n",
    "Determine the relationship of PER (Player Efficiency Rating) to Salary via a visualization of the data.\n",
    "\n",
    "\n",
    "NBA 2014 Players Dataset: [http://bit.ly/gtnbads](http://bit.ly/gtnbads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import urllib2\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the Data\n",
    "\n",
    "You have a couple of options of fetching the data set to begin your analysis:\n",
    "\n",
    "1. Click on the link above and Download the file. \n",
    "2. Write a Python function that automatically downloads the file and writes it to disk. \n",
    "\n",
    "In either case, you'll have to be cognizant of where the CSV file lands. Here is a quick implementation of a function to download a URL at a file and write it to disk. Note the many approaches to do this as outlined here: [How do I download a file over HTTP using Python?](http://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(url, path):\n",
    "    \"\"\"\n",
    "    Downloads a URL and writes it to the specified path.\n",
    "    Note the use of \"with\" to automatically close files.\n",
    "    \"\"\"\n",
    "    response = urllib2.urlopen(url)\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(response.read())\n",
    "    \n",
    "    response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn: use the above function to download the data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write the Python to download the file here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "Now that we have the CSV file that we're looking for, we need to be able to open the file and read it into memory. The trick is that we want to read only a single line at a time - consider really large CSV files. Python provides memory efficient iteration in the form of `generators` and the `csv.reader` module exposes one such generator, that reads the data from the CSV one row at a time. Moreover, we also want to parse our data so that we have specific access to the fields we're looking for. The `csv.DictReader` class will give you each row as a dictionary, where the keys are derived from the first, header line of the file. \n",
    "\n",
    "Here is a function that reads data from disk one line at a time and `yield`s it to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    # First open the file\n",
    "    with open(path, 'r') as f:\n",
    "        # Create a DictReader to parse the CSV\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Yield each row one at a time.\n",
    "            yield row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn: use the above function to print out the first row of the CSV!**\n",
    "\n",
    "To do this, you'll need to pass into the function the path of the data you downloaded. The function \"returns\" a generator, so you'll need to use a `for` loop in order to access the data. Note that `break` will stop a `for` loop from running. E.g. the code:\n",
    "\n",
    "```python\n",
    "for idx in xrange(100):\n",
    "    if idx > 10:\n",
    "        break\n",
    "```\n",
    "\n",
    "Will stop the for loop after 10 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Write the Python to print the first row of the CSV here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "In this section, you'll use the CSV data to write computations for mean, median, mode, minimum, and maximum. These summary statistics can be computed inside of a single function, which will take as an argument the field that you want to compute the statistics upon. The function will then load the data from disk, make the computation, and return a dictionary with the summary statistics. \n",
    "\n",
    "The function stub is below - it's up to you to fill in the details. Test your function by running the print command in the following cell. Note that what we're looking for is the act of solving the _algorithm_ involved in computing summary statistics. In real life, you'll use _tools_ for solving these problems (like Pandas). Please attempt to make the computations using only the `sorted` (and `itemgetter`) and `Counter` tools already imported for you. \n",
    "\n",
    "(You'll have to sort the data in order to get the Median, and you'll need something to keep track of frequency, e.g. the Mode). How do you find out about `sorted`, `itemgetter`, and `Counter` in Python?\n",
    "\n",
    "**Your turn: fill in the below function to return a dictionary of summary statistics for a specific field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"minimum\": null, \n",
      "    \"median\": null, \n",
      "    \"mode\": null, \n",
      "    \"maximum\": null, \n",
      "    \"mean\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def statistics(path, field):\n",
    "    \"\"\"\n",
    "    Takes as input a path to `read_csv` and the field to\n",
    "    compute the summary statistics upon.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Uncomment below to load the CSV into a list\n",
    "    # data = list(read_csv(path))\n",
    "    \n",
    "    # Fill in the function here\n",
    "    \n",
    "    return {\n",
    "        'mean': None,\n",
    "        'median': None,\n",
    "        'mode': None,\n",
    "        'maximum': None,\n",
    "        'minimum': None,\n",
    "    }\n",
    "\n",
    "# Runs the function to ensure everything is working\n",
    "print json.dumps(statistics('', 'SALARY'), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep playing with the above function to get it to work more efficiently or to reduce bad data in the computation - e.g. what are all those zero salaries? \n",
    "\n",
    "\n",
    "## Visualization\n",
    "\n",
    "Congratulations if you've made it this far! It's time for the bonus round!\n",
    "\n",
    "You've now had some summary statistics about the salaries of NBA players, but what we're really interested in is the relationship between `SALARY` and the rest of the fields in the data set. The `PER` - Player Efficiency Rating, is an aggregate score of all performance statistics; therefore if we determine the relationship of `PER` to `SALARY`, we might learn a lot about how to model NBA salaries. \n",
    "\n",
    "In order to explore this, let's create a scatter plot of `SALARY` to `PER`, where each point is an NBA player.\n",
    "\n",
    "Visualization is going to require a third party library, select one of the following:\n",
    "\n",
    "- matplolib\n",
    "- seaborn\n",
    "- bokeh\n",
    "- pandas\n",
    "\n",
    "And `pip install` it. Follow the documentation to create the scatter plot inline in the notebook in the following cells. (Our recommendation is Bokeh - it is a bit more interactive). Note, you probably already have matplotlib, so that might be the simplest if you're having trouble with installation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Insert your Python to create the visualization here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
